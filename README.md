# LogProcessing

* 说明

由于生成的log文件较大，在github中只保留了一个log文件(10M大小)。

* 要求

实现生成日志、解析日志、数据入库，日志的格式为 [时间][日志类型]{json}
具体要求如下：
1. 时间的格式期望为2015-01-27 16:03:45 +0800，但是可以省略掉”+0800“；日志类型只包含数字、字母、下划线，json为标准格式。
日志类型的范围，需要提前定义，每种日志类型对应的Json内容的key设计为固定的。比如定义的日志类型包含 "Login","Logout","Chat" ,”Trade“,"Fight" 等等，假设Login这个日志类型，对应的json的key 的内容为{"when"，"where"，"why"，"what"，"who"，"How"，"Detail"}。日志文件的大小有限制，即假设生成一段时间的数据，会包含很多个日志文件，比如10M一个文件。
2. 日志的样式期望满足给定格式，[时间][日志类型]{json}，但是需要在生成日志时，给解析制造点麻烦（=。=,并非严格按照规则生成，越像越完美）。比如日志样例为
[2015-01-27 16:03:45 +0800][Login],{"why":0,"when":1422345825,"what":"4001",”who”:”abc”,”How”:”hand by”,”Deatil”：”心机表”,”where”:”home”,”else”:”other”}
注意 json中的key ，可能和 1中定义的key不同，比如1中定义Login的key为
{"when"，"where"，"why"，"what"，"who"，"How"，"Detail"}，实际生成的日志未必是这样，可能多其他的key，也可能有些key缺失。
3. 实现对日志的解析（期望是多线程的），并在解析后插入到Mysql数据库
4. 处理你能想到的异常情况；制定数据导入的方案与策略；处理的日志量不得少于200M
